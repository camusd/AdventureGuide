{% extends "base.html" %}
{% block content %}
<!-- TODO add more headers to make it look better -->
  <h1 class="text-center">How to use Jenkins CI with AWS EC2 and Virtual Private Cloud with Mongodb database for Python Flask</h1>
  <section id="step1">
    <div class="container">
      <div class="row">
        <h3>Step 1: Setup AWS Instances</h3>
        <p>
          The first step we will need to get the ball rolling is to configure our Amazon Web Service (AWS) Elastic Compute Cloud (EC2) instances and a AWS Virtual Private Cloud (VPC) environment. We will also need to setup our AWS Identity &amp; Access Management service (IMA). After finishing this step, you will have an ECS instance and an EC2 instance setup with Mongodb running in an AWS Virtual Private Cloud, setup with proper security and permissions for one user.
        </p>
        <h4>Setup AWS Account</h4>
        <p>
          The first thing we will need to do in this step is to set up an AWS account. Open <a href="http://aws.amazon.com/">http://aws.amazon.com/</a>, and choose create an AWS account. Follow the online instructions to create an account. Don't forget to document your AWS account number, as it will be needed in the following steps.
        </p>
        <p>
          Now that we have an account created, it is time to setup an IAM user. Amazon recommends that the root account is never used except to create the administrator group and the first user account. After that, the administrator account can be used to create new users and instances.
        </p>
        <p>
          Sign in to your AWS account as root and navigate to the IAM console. It is listed under Security &amp; Identity section of the AWS dashboard. From the IAM console, navigate to Groups and create a new group. We will name this group Administrators. Click next step. On the next page, check the AdministratorAccess policy. This can be found by using the search box. Click next step and create the group.
        </p>
        <p>
          Now that we have a group, it is time to create the first user. From the IAM console, choose Users and then create user. Choose a user name for the user and clear the checkbox to generate an access key for each user, then choose create. On the next page, click the user we just created. In the Groups tab, click add user to groups. Check the administrators group that we created earlier and click add to groups. Then, choose the security credentials tab and choose manage password. From here, select assign a custom password and type in a password and password confirmation and click apply. Finally, sign in to the new user by navigating to <a href="#"> https://your_aws_account_id.signin.aws.amazon.com/console/</a> using your AWS account id.
        </p>
        <h4>Create AWS ECS Repository</h4>
        <p>
          It is now time to setup the build environment. From the AWS dashboard, select the EC2 console. From the navigation bar, select a region for your key pair. This region should be the same region that you intend to run your ECS instance from. In the navigation pane on the left hand side of the console, select key pairs under network &amp; security. Enter a name for the key pair and click create. Save the private key (file extention .pem) in a safe place. Make sure that only you have permission to read the private key by running chmod 400 on the private key file.
        </p>
        <p>
           We will now set up the ECS instance. From the AWS dashboard, navigate to the ECS console. Click get started and check both boxes. This will create a sample application on an ECS Cluster, as well store the container images securely with Amazon Container Registry. Click continue and on the next page give the repository a name, then click continue again. This will create the repository. Amazon will provide a few steps to setup the docker image.
        </p>
        <p>
          You will need to install both AWS commandline interface and docker. You can follow the links that are provided by Amazon on the page, or if you are using a Debian flavor of Linux you can run apt install awscli and apt install docker. Once AWS commandline interface is installed, you will need to run aws configure before you run any of the commands Amazon provided. This will ask for your access key id and secret key, so be prepared to provide them. You may need to provide sudo for the commands Amazon provides. Before running any of the Amazon provided commands, we will need a functioning application that we will dockerize. You can use any application, but this guide will be using a Python Flask application. If you do not have a flask web app, go ahead and clone the app that this guide is hosted on by entering the following command in your terminale: <code>git clone https://github.com/camusd/helloCloud.git</code>. In the main directory of the application, create a new file named Dockerfile. It should look like this
          <pre>
            FROM python:2-onbuild
            CMD [ "python", "./application.py" ]
          </pre>
          Follow these steps and click continue.
        </p>
        <h4>Create AWS Stack</h4>
        <p>
          It is now time to launch our Amazon VPC, which serves as our network infastructure. This will create the public and private subnets that we need to allow our Mongodb database to communicate with our webserver. We will use an AWS CloudFormation template to create the VPC as well as the EC2 instance and Elastic Block Store (EBS). The template will also download MongoDB for us.
        </p>
        <p>
          From the AWS dashboard, navigate to the CloudFormation console. From there, click create stack. We will be using a template that can be downloaded from this url: <a href="https://s3.amazonaws.com/quickstart-reference/mongodb/latest/templates/MongoDB-VPC.template">https://s3.amazonaws.com/quickstart-reference/mongodb/latest/templates/MongoDB-VPC.template</a>. Choose upload template and select the template you downloaded and click next. Give the stack a name and confirm that the region in the top right corner of the page is correctly set to your region and that the availability zones are correctly set Set the ClusterShardCount to 1. Also, make sure to select the keypair we created for the EC2 instance in the KeyName field and click next. Click next on the options page and then click create on the next page.
        </p>
        <p>
          Our next step is spin up an AWS EC2 instance. This instance will be where we will deploy our web application. From the AWS dashboard, select EC2. In the EC2 console, click launch instance. We will be launching an Amazon Linux AMI instance. After selecting that, choose the t2.micro option and click next. On the next page, we will keep the defaults except for the Network and the IAM role. We will need to click the create new IAM role button. This will open a new tab. Create a new policy and name it. Then select AmazonEC2FullAccess from the list of policys and click next and create role on the next page. Navigate back to the previous tab and select the IAM role we just created. This will require refreshing the page. Then, we will need to choose the vpc we created earlier from the Network dropdown. We will also want to select to use a public ip. Then click next on the next three pages. On the security group page, we will need to open ports tcp/22 and tcp/80. By default, tcp/22 will be open, so we need to add a new rule for tcp/80. Click add rule, and in the type dropdown, select HTTP. Then click review and launch, followed by launch. AWS will prompt you to select the key pair we created earlier. find this keypair from the dropdowns and click launch instance.
        </p>
        <h4>Test AWS Stack</h4>
        <p>
          Now that we have created our stack, it is time to test it. Navigate to the EC2 console and select the NAT instance from the list of running instances and click connect. Follow the prompt Amazon gives you to ssh into the instance. Now that we are ssh'd in, we can use this instance to connect to our mongo nodes. First, we need to copy the ssh key into the NAT instance. Run this command on your local console (not the NAT): <code>scp â€“i mykey.pem mykey.pem ec2-user@NAT-public-ip:/home/ec2-user/mykey.pem</code> Go back to the EC2 dashboard, and this time select the primary mongo node and click connect. Follow the prompt again, but this time ssh into the instance from the NAT instance you ssh'd into earlier.
          Now that we are in the primary Mongodb node, we will test the system by running <code>mongo --version</code> and confirming that mongo is installed.
        </p>
      </div>
    </div>
  </section>
  <section id="step2">
    <div class="container">
      <div class="row">
        <h3>Step 2: Configure AWS Instances</h3>
        <p>
          With our stack created, it is now time to begin configuring our stack in preperation for deploying our app. If you are following along with the provided flask application, you may checkout the jenkins-aws branch to see the full implementation of the changes we will be making to configure the app for AWS deployment.
        </p>
        <h4>Configure Web App EC2 Instance</h4>
        <p>
          Connect to your Web App EC2 Instance the same way we connected to the mongo PrimaryReplicaNode. So, we need to first ssh into the NAT instance, and then ssh into the web app instance. Before doing this, however, you will need to edit the NAT security group. From the EC2 dashboard, navigate to Security Groups on the left column. Select the security group named your_stack_name-NATSecurityGroup, click the outbound tab, and select edit. You will need to add a custom SSH rule that allows access to the destination that corresponds to your web app private ip address. You can find the private ip address by clicking connect on that EC2 instance from the EC2 dashboard. After adding this rule, you can connect to the EC2 instance from the NAT instance using ssh.
        </p>
        <p>
          Now that we are finally connected to our EC2 instance, it is time to configure it. First, we will need to become root by typing <code>sudo su -</code>. Now we will run a few commands to install the software we will need. First, we will get docker, nginx, and git.
          <pre>
            # yum update -y
            # yum install -y docker nginx git
          </pre>
          Next we will need to install Jenkins. Installing Jenkins on AWS requires adding the Jenkins repository.
          <pre>
            # wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo
            # rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key
            # yum install jenkins
          </pre>
          Jenkins uses port TCP/8080, so we will have to configure nginx as a proxy. We will do this by editing /etc/nginx/nginx.conf and changing the server configuration. It should end up looking like this:
          <pre>
            server {
              listen       80;
              server_name   _;

              location / {
                      proxy_pass http://127.0.0.1:8080;
              }
            }
          </pre>
          Now we will setup Jenkins to build our Docker images by adding Jenkins to our Docker group.
          <pre>
            # usermod -a -G docker jenkins
          </pre>
          Finally, we will start Docker, Jenkins, and ngingx and make sure they start up on reboot.
          <pre>
            # service docker start
            # service jenkins start
            # service nginx start
            # chkconfig docker on
            # chkconfig jenkins on
            # chkconfig nginx on
          </pre>
          Now we will want to configure nginx as a reverse proxy for Jenkins. To do this we will need to edit the nginx config file at /etc/nginx/nginx.conf and add this code to the server section:
          <pre>
            server {
                listen 80;
                listen [::]:80 default ipv6only=on;
                server_name _;

                # Load configuration files for the default server block.
                # include /etc/nginx/default.d/*.conf;

                location / {
                        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                        proxy_set_header Host $http_host;
                        proxy_redirect off;

                        if (!-f $request_filename) {
                                proxy_pass http://127.0.0.1:8080;
                                break;
                        }
                }
            }
          </pre>
        </p>
        <h4>Configure Jenkins for Docker</h4>
        <p>
          With our EC2 instance now properly setup, it is time to configure Jenkins to be able to use the ECS CLI. We will need to change from root to the jenkins user by typing this into the terminal that is ssh'd into the EC2 instance:
          <pre>
            # sudo -su jenkins
            > aws configure
          </pre>
          This will ask you for your AWS access key and secret key, so be prepared to provide them. After configuring the AWS CLI, we will need to log into docker hub. If you do not have a docker hub account, go create one now. Then, type <code>docker login</code> into your console and provide your docker hub username and password.
        </p>
        <p>
          Now it is time to create a task definition for our docker image. We will need to select ECS from the AWS dashboard. From the ECS console, select task definitions in the left column. Near the bottom of the page, click the configure JSON button and type in this:
          <pre>
          {
              "family": "flask-signup",
              "containerDefinitions": [
                  {
                      "image": "your-repository/flask-signup:v_%BUILD_NUMBER%",
                      "name": "flask-signup",
                      "cpu": 10,
                      "memory": 256,
                      "essential": true,
                      "portMappings": [
                          {
                              "containerPort": 5000,
                              "hostPort": 80
                          }
                      ]
                  }
              ]
          }
          </pre>
          You can find your repository under the repositories tab in the left column. Click create to create the task definition for the Jenkins job.
        </p>
        <p>
          Now we will create a load balancer for our VPC. Navigate to the EC2 console and select load balancers from the left hand column and click create load balancer. Give the load balancer a name and select our VPC from the create LB inside dropdown. Select the subnet that we will use for the load balancer, and click next. Leave the next page at defaults and click next and next again on the next page. Finally, on the last page change the ping path to be a single / and leave the other fields default and click next on this page and the next. Finally, register your load balancer to your EC2 instances, click next two more times, and click create.
        </p>
        <p>
          Now that we have that underway, we can create our service. Enter this into the AWS Jenkins user console:
          <pre>
            # aws ecs create-service --cluster default --service-name flask-signup-service --task-definition flask-signup --load-balancers loadBalancerName=elb-flask-signup-1985465812,containerName=flask-signup,containerPort=5000 --role ecs-service-role --desired-count 0
            {
                "service": {
                    "status": "ACTIVE",
                    "taskDefinition": "arn:aws:ecs:us-east-1:123456789012:task-definition/flask-signup:1",
                    "desiredCount": 0,
                    "serviceName": "flask-signup-service",
                    "clusterArn": "arn:aws:ecs:us-east-1:123456789012:cluster/default",
                    "serviceArn": "arn:aws:ecs:us-east-1:123456789012:service/flask-signup-service",
                    "runningCount": 0
                }
            }
          </pre>
          This will create a service specifying the task definition and ELB name.
        </p>
      </div>
    </div>
  </section>
  <section id="step3">
    <div class="container">
      <div class="row">
        <h3>Configure and Deploy Jenkins Build</h3>
        <p>
          It is finally time to get Jenkins integrated into our build. After this final step, we will have a Jenkins job that will run whenever a change is commited to our GitHub repository, triggering the build process in Jenkins.
        </p>
        <p>
          From the Jenkins dashboard, located at our public dns address for our application EC2 instance, click new item and select freestyle project job. Give the job a name and click ok. Under GitHub Project, add the GitHub repository url for your project. Under source code management, provide the same url. For Build Triggers, select build when a change is pushed to GitHub. Finally, in the Build section, add a Docker build and publish step to the job and configure it to publish to DockerHub and add a tag.
        </p>
        <img src="../static/images/build_step_docker.png" />
        <p>
          The repository name should specify the name of the Docker image to be published and the image name. The repository name needs to be the same as the one used in the flask_signup.json. Next, we will create the Execute script. It should look like this:
          <pre>
            #!/bin/bash
            SERVICE_NAME="flask-signup-service"
            IMAGE_VERSION="v_"${BUILD_NUMBER}
            TASK_FAMILY="flask-signup"

            # Create a new task definition for this build
            sed -e "s;%BUILD_NUMBER%;${BUILD_NUMBER};g" flask-signup.json > flask-signup-v_${BUILD_NUMBER}.json
            aws ecs register-task-definition --family flask-signup --cli-input-json file://flask-signup-v_${BUILD_NUMBER}.json

            # Update the service with the new task definition and desired count
            TASK_REVISION=`aws ecs describe-task-definition --task-definition flask-signup | egrep "revision" | tr "/" " " | awk '{print $2}' | sed 's/"$//'`
            DESIRED_COUNT=`aws ecs describe-services --services ${SERVICE_NAME} | egrep "desiredCount" | tr "/" " " | awk '{print $2}' | sed 's/,$//'`
            if [ ${DESIRED_COUNT} = "0" ]; then
                DESIRED_COUNT="1"
            fi

            aws ecs update-service --cluster default --service ${SERVICE_NAME} --task-definition ${TASK_FAMILY}:${TASK_REVISION} --desired-count ${DESIRED_COUNT}
          </pre>
          This script will create a new task revision when run. We just need to configure it so that the script is triggered upon the build process of Jenkins when pushing to the GitHub repository. This requires configuring a GitHub service hook. Go to the GitHub repository settings page and select Webhooks and Services. Under the services dropdown, select Jenkins (GitHub plugin). For the Jenkins hook url, enter: http://your_user_name:your_password@your_EC2_DNS_name/github-webhook/.
        </p>
        <img src="../static/images/awslab_github_jenkins_webhook.png" />
        <p>
          Congradulations, you have now integrated Jenkins into a Docker build environment hosted on AWS using Flask and MongoDB setup with a VPC. Now after every push to the server, you can have a Jenkins job run. This can be used to run a test sweet after every push to ensure that the code is working!
        </p>
{% endblock %}
